{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankLoan:\n",
    "\n",
    "    def __init__(self, input_path=None):\n",
    "        self.input_path = input_path\n",
    "\n",
    "    # Read CSV file from source location\n",
    "    def extract(self):\n",
    "        # spark.read.options(header=\"true\", inferSchema=\"true\", delimiter=\",\").csv(self.input_path)\n",
    "        return spark.sql(\"select * from worldbankloan_db.loanstatement\")\n",
    "\n",
    "    # Select Columns with transformations\n",
    "    def transform(self, df):\n",
    "        \n",
    "        # How many days taken to sign the loan and the other was how many days taken for repayment.\n",
    "        bsq1 = df.withColumn(\"Days_to_Sign_the_loan\",F.datediff(\"agreement_signing_date\",\"board_approval_date\"))\\\n",
    "                .withColumn(\"Time_taken_for_Repayment\",F.when(F.col(\"loan_status\") == \"Fully Repaid\", F.datediff(\"last_repayment_date\",\"first_repayment_date\")).otherwise(F.lit(None)))\n",
    "        \n",
    "        # Find the  top three countries had huge amount of loans and it quickly dropped.\n",
    "        bsq2 = df.groupby(\"country\")\\\n",
    "                .agg(F.sum(\"orig_prin_amount\").alias(\"Total_Amount\"))\\\n",
    "                .orderBy(F.col(\"Total_Amount\").desc())\\\n",
    "                .limit(3)\n",
    "        \n",
    "        # Which countries that had at least one cancellation with the assumption that they had borrowed enough number of loan\n",
    "        set_ = set(df.select(\"country\").where(F.col(\"loan_status\") == \"Fully Cancelled\").rdd.flatMap(lambda x:x).collect())\n",
    "        bsq3 = df.groupBy(\"country\")\\\n",
    "                .agg(F.count(\"*\").alias(\"Total_Requests\"))\\\n",
    "                .where(F.col(\"country\").isin(set_))\\\n",
    "                .orderBy(F.col(\"Total_Requests\").desc())\n",
    "        \n",
    "        # Find the average repayment period for a country \n",
    "        bsq4 = bsq1.groupBy(\"country\")\\\n",
    "                    .agg(F.round(F.avg(\"Time_taken_for_Repayment\")).alias(\"Average_repayment_days\"))\\\n",
    "                    .orderBy(F.col(\"country\"))\n",
    "        \n",
    "        \n",
    "        return (bsq1,bsq2,bsq3,bsq4)\n",
    "    \n",
    "    # Save the final Dataframe in your desired location in parquet/json format\n",
    "    def load(self, bsq1,bsq2,bsq3,bsq4):\n",
    "        # transformedDF.write\\\n",
    "        #     .bucketBy(4,\"Country\")\\\n",
    "        #     .saveAsTable(\"country_wise_loans\", format=\"parquet\")\n",
    "        return bsq4.show(10)\n",
    "        \n",
    "    # Pipelining previous functions\n",
    "    def run(self):\n",
    "        self.load(*self.transform(self.extract()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local')\\\n",
    "                                .appName('Bank_Loan')\\\n",
    "                                .enableHiveSupport()\\\n",
    "                                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------+\n",
      "|            country|Average_repayment_days|\n",
      "+-------------------+----------------------+\n",
      "|            Albania|                  null|\n",
      "|            Algeria|                3727.0|\n",
      "|             Angola|                  null|\n",
      "|Antigua and Barbuda|                  null|\n",
      "|          Argentina|                3642.0|\n",
      "|            Armenia|                5295.0|\n",
      "|          Australia|                4937.0|\n",
      "|            Austria|                6321.0|\n",
      "|         Azerbaijan|                5047.0|\n",
      "|       Bahamas, The|                4511.0|\n",
      "+-------------------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bk = BankLoan(input_path=\"data/IBRD_Statement_Of_Loans_-_Historical_Data.csv\")\n",
    "bk.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "573696f18ae3f3d76bae6f96c05f69c364c1e77108f829ea9973fae2e381f9e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
